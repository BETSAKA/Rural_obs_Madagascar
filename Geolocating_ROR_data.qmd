---
title: "Georeferencing Annual Household Surveys in Rural Madagascar: A Comprehensive Analysis of Observatories (1995-2014)"
author: "Florent Bédécarrats"
format:
  html:
    toc: true
    output-file: index.html
    embed-resources: true
    standalone: true
    code-fold: true
    
execute:
  warning: false
  error: false
editor: visual
editor_options: 
  chunk_output_type: console
---

## Introduction

This document serves as a technical appendix accompanying the paper tied to opening of the data collected by the Rural observatory network (ROR, for its acronym in French) from 1995 to 2014. The ROR was a panel survey system that monitored the living conditions of populations in selected localities representing the diversity of rural contrxts in Madagascar. While the ROR data underwent a rigorous supervision and curation process during its collection phase, complemented by an exhaustive harmonization effort subsequently, its geolocation attributes remain largely incomplete. This absence of usable geographic reference in the data hinders its integration with other spatially-referenced datasets, particularly when one contemplates its utility in realms such as public policy formulation or project evaluation.

This study endeavors to bridge this gap through a meticulous georeferencing process. The primary objective is to reconcile the somewhat erratic spatial denominations, or toponyms, found within the ROR dataset with a more standardized spatial database. Ultimately, this effort aims to establish a congruent correspondence between each observation from the ROR survey and both a polygon representing a Malagasy municipality and a referential village point.

To achieve this in a reliable way that enables external verification and subsequent improvements, we harness the capabilities of computational notebooks (Quarto format). As interactive computing environments, these notebooks facilitate an amalgamation of code, computational output, explanatory text, and multimedia resources. We use R for the code, as it offeres a high versatility to handle spatial data, complex surveys and textual informaiton. By adopting this methodology, we aim to bolster the reliability and usability of the ROR data for spatial analysts and researchers.

```{r load_libraries}
library(tidyverse)    # A series of packages for data manipulation
library(haven)        # Required for reading STATA files (.dta)
library(labelled)     # To work with labelled data from STATA
library(sf)           # for spatial data handling
library(tidyverse)    # for data wrangling and visualization
library(stringdist)   # for string distance and matching
library(tmap)         # for mapping
library(fuzzyjoin)    # for fuzzy joining
library(readxl)       # Read data frames to Excel format
library(writexl)      # Write data frames to Excel format
library(gt)           # for nicely formatted tables
library(cowplot)      # to combine plots
```

## Revisiting the Rural Observatories (ROR) of Madagascar

The Rural Observatory Network (ROR) was established as part of the Madio project (1994-1999), a technical assistance program of the IRD to the national statistical institute (INSTAT) of Madagascar, as an innovative mechanism for monitoring and analyzing the country's agricultural sector. This initiative arose from the urgent need to compile statistics on the agricultural industry due to the breakdown of the existing statistical system following the socialist era and political turmoil in the country. 

Four initial observatories were established in 1995, each representing a different set of agricultural challenges in the country's diverse ecosystems. From 1995 to 2015, 22 other observatories were created, and existing were abandoned (see @fig-hist-ror). The ROR were supported by a variety of donors and NGOs during this period: European union, AFD, World Bank, GTZ, Swiss cooperation, Care and Rio Tinto. The selection of observation sites was based on a combination of criteria, including agroclimatic areas, dominant production systems, population density, accessibility, and the presence of support structures and development projects. These observatories aimed to provide insights into the dynamics of Malagasy agriculture, covering a range of issues such as isolated coastal communities of fishermen and livestock farmers, the impact of trade liberalization on vanilla producers, family smallholdings in the central plateau, and the restructuring of large irrigated rice-growing areas. 


```{r}
#| label: fig-hist-ror
#| fig-cap: "Coarse location of rural observatory and survey years"

# Define a function to load and count surveys per observatory for a given year
load_and_count <- function(year, factorize = FALSE) {
  # Define file path
  file_path <- paste0("Données ROR/enter/", year, "/res_deb.dta")
  
  # Load data
  data <- read_dta(file_path)
  
  # Extract label and convert to factors if option
  if (factorize) {
    data <- data %>%
      mutate(across(everything(), as.character),
             across(where(is.labelled), ~ as.character(as_factor(.))))
  }
  
  # Count surveys per observatory
  count_data <- data %>%
    group_by(j0) %>%
    summarise(survey_count = n()) %>%
    ungroup() %>%
    mutate(year = year)  # Add year column
  
  return(count_data)
}

# Generate a list of years
years <- 1995:2014

# Use purrr::map_df to loop through each year and bind results
obs_count <- map_df(years, load_and_count) %>%
  # Remove rows with observatory "7 " and "NA", whch are errors
  filter(j0 != 7 & !is.na(j0)) %>%
  rename(observatory = j0)

# Read observatory names
observatory_names <- readxl::read_xlsx("Observatory_names.xlsx") %>%
  select(code, observatory_name = name)

# PAss it to wide.
obs_count <- obs_count %>%
  left_join(observatory_names, by = c("observatory" = "code")) %>%
  group_by(observatory_name, year) %>%
  summarise(survey_count = sum(survey_count))

obs_count_wide <- obs_count %>%
  pivot_wider(names_from = year, values_from = survey_count)

# Add observatory approximate location
locations <- tibble(
  code = c(1, 2, 3, 4, 12, 13, 15, 16, 21, 22, 23, 24, 31, 25, 41, 42, 43, 51, 
           44, 45, 61, 17, 18, 19, 71, 52),
  name = c("Antalaha", "Antsirabe", "Marovoay", "Toliara", "Antsohihy", 
           "Tsiroanomandidy-Bongo", "Farafangana", "Ambovombe", 
           "Alaotra", "Manjakandriana", "Toliara littoral", 
           "Fenerive Est", "Bekily", "Mahanoro", "Soaviandriana-Itasy", 
           "Menabe-Belo", "Fianarantsoa", "Tsivory", "Morondava", "Manandriana", 
           "Tanandava", "Ihosy", "Ambohimahasoa", "Manakara", "Tolanaro", 
           "Menabe-Nord-Est"),
  latitude = c(-14.8833, -19.8659, -16.1000, -23.3558, -14.8796, -18.7713, 
               -22.8167, -25.1667, -17.8319, -18.9167, -23.3558, -17.3500, 
               -24.6900, -19.9000, -19.1686, -19.6975, -21.4527, -24.4667, 
               -20.2833, -20.2333, -22.5711, -22.4000, -20.7145, -22.1333, 
               -25.0381, -20.5486),
  longitude = c(50.2833, 47.0333, 46.6333, 43.6683, 47.9875, 46.0546, 47.8333, 
                46.0833, 48.4167, 47.8000, 43.6683, 49.4167, 45.1700, 48.8000,
                46.7354, 44.5419, 47.0857, 45.4667, 44.2833, 47.3833, 45.0439, 
                46.1167, 47.0389, 48.0167, 46.9562, 47.1597))

obs_count <- left_join(obs_count, locations, by = c("observatory_name" = "name"))


madagascar <- st_read("../Entités administratives/OCHA_BNGRC frontières administratives/mdg_admbnda_adm0_BNGRC_OCHA_20181031.shp",
                      quiet = TRUE)

# Sort locations by latitude to generate sequence numbers
locations <- locations %>%
  arrange(desc(latitude)) %>%
  mutate(seq_num = 1:n())

# Create map plot with labels
map_plot <- ggplot(data = madagascar) +
  geom_sf(fill = "lightgray") +
  geom_point(data = locations, aes(x = longitude, y = latitude, color = name), 
             size = 3) +
  geom_text(data = locations, aes(x = longitude, y = latitude, label = seq_num), 
            vjust = -1, hjust = 1, size = 3) + 
  theme_void() +
  theme(legend.position = "none")

# Add sequence numbers to observatory names in obs_count dataframe
obs_count <- obs_count %>%
  left_join(locations %>%
              select(name, seq_num), 
            by = c("observatory_name" = "name")) %>%
  mutate(observatory_with_num = paste0(seq_num, ". ", observatory_name))

# Create timeline plot using modified obs_count with observatory_with_num
timeline_plot <- ggplot(obs_count, 
                        aes(x = year, 
                            y = fct_reorder(observatory_with_num, latitude), 
                            color = observatory_name)) +
  geom_point(aes(size = survey_count), show.legend = F) +
  theme_minimal() +
  labs(y = NULL, x = NULL) +
  theme(axis.text.y = element_text(size = 8),
        legend.position = "none")

# Stitch the plots together
combined_plot <- plot_grid(map_plot, timeline_plot, rel_widths = c(1.3, 2))

ggsave("../../Protocole/Figures/ROR_history.png", plot = combined_plot, 
       width = 10, height = 7, dpi = 300)

print(combined_plot)
```

This set-up was particularly significant for rural development and macroeconomic policy decisions. In the mid-1990s, This initiative was motivated by an urgent need to compile statistics on the agricultural industry due to the breakdown of the existing statistical system. This became crucial as Madagascar experienced significant changes in its rural areas since 1980, particularly with the liberalization of pricing and marketing structures. The Madagascar ROR arose as a part of the broader trend of socio-economic observatories that emerged in sub-Saharan Africa in the 1980s. These observatories are information systems designed to assess changes in society and their impact on specific populations, emphasizing poverty reduction, combating exclusion, and promoting sustainable human development.

### Challenges for opening the data

In this notebook, our primary objective is to enhance the georeferencing of the ROR survey data for open data sharing. The initial ROR survey, initiated in 1995, recorded geographical information in varying formats: from "village" to a combination of "municipality", "village", and "site". A significant challenge arose from the fact that while data collection started in 1995, municipalities were only formally established in 1994, with several years required for stabilization. The inherent fluidity in toponyms, predominantly derived from oral traditions, resulted in varied written representations. Our endeavor is to identify, disambiguate, and georeference observations recorded in the ROR data, adopting the Common Operational Datasets (CODs) as a reference, which has been collaboratively defined by OCHA and Madagascar's BNGRC (National Disaster Management Office).

CODs stand as the bedrock for all preparedness and response operations, especially within the humanitarian sector. Adopted by the IASC in 2008 and revised in 2010, these datasets are pivotal for facilitating informed decision-making during the critical initial hours of a crisis. By ensuring consistency among stakeholders, they simplify data management and establish a shared operational picture of a crisis. Particularly relevant for our purpose is the incorporation of P-codes in CODs. These unique geographic identification codes, found in both Administrative Boundary CODs (COD-ABs) and Population Statistics CODs (COD-PSs), surmount challenges posed by variations in placenames and spellings. For instance, in Madagascar, 81 different administrative level 4 (ADM4) features are labeled "Morafeno", with six of these existing within ADM3 features also termed "Morafeno", distinguishable solely by their unique ADM2 features.

P-codes act as reliable geographic identifiers, eliminating errors arising from identical or variably spelled geographic locations. Leveraging the HDX platform, an open platform for cross-crisis data sharing, we fetch this data to ensure the accurate georeferencing of our ROR data. By harnessing the standardized and official spelling of places provided by P-codes, we can amalgamate, harmonize, and analyze data from diverse sources, offering a comprehensive, geo-accurate view of the survey's findings.

## Data Description and Initial Exploration with R

### ROR survey data

The ROR survey data is organized in a collection of year-specfic folders ranging from 1995 to 2015. Each yearly folder houses multiple .dta files (Stata data format) -- about 85 per year -- with diverse filenames such as "res_as.dta" and "res_bp.dta". Although there's an element of harmonization achieved, especially regarding certain variables and household identifiers, the data varies in terms of geographical granularity. Initial years primarily provide a singular field denoting the village name. As the years progress, this evolves to include a municipality name, and in the latter years, an additional "site" name occasionally appears. A comprehensive overview of the observations can be gleaned from the "res_deb.dta" files within each year.

```{r}
# Function to extract variable info for a given year and file
extract_variable_info <- function(year, file) {
  
  file_path <- paste0("Données ROR/enter/", year, "/", file)
  
  if (!file.exists(file_path)) return(tibble())
  
  data <- read_dta(file_path, n_max = 0)
  
  tibble(
    file_name = file,
    variable_name = names(data),
    variable_label = var_label(data) %>% as.character(),
    year = year)
}

# Obtain all years from the directory structure
years <- list.dirs("Données ROR/enter/", recursive = FALSE, full.names = FALSE)

# Use the tidyverse approach to map over years and files
all_vars <- map_df(years, ~{
  files_for_year <- list.files(paste0("Données ROR/enter/", .x), pattern = "\\.dta$", full.names = FALSE)
  map_df(files_for_year, extract_variable_info, year = .x)
})

# Convert any NULL values in variable_label to "NA"
all_vars$variable_label[is.na(all_vars$variable_label)] <- "NA"

# Consolidate the information using the tidyverse approach
variable_dictionary <- all_vars %>%
  group_by(file_name, variable_name) %>%
  arrange(year) %>%  
  summarise(
    variable_label = first(variable_label[variable_label != "NA"] %||% "NA"),
    years_present = list(unique(year))
  ) %>%
  ungroup() %>%
  mutate(years_present = map_chr(years_present, ~paste(.x, collapse = ",")))

# Write the variable dictionary to an Excel file
write_xlsx(variable_dictionary, "ROR_Variable_Dictionary.xlsx")
```

The code block above creates a data dictionnary, which you can download by clicking [on this link](ROR_Variable_Dictionary.xlsx).

### Administrative boundaries

The "Madagascar Subnational Administrative Boundaries" dataset is sourced from the Common Operational Datasets (CODs), which offer authoritative reference datasets for decision-making during humanitarian operations. Specifically designed to streamline the discovery and exchange of pivotal data, CODs ensure uniformity and use the 'best available' datasets. This particular dataset focuses on administrative boundaries, including gazetteers with P-codes, facilitating organized humanitarian assessments and data management. P-codes act as unique identifiers for every administrative unit and populated area, ensuring standardization in nomenclature. When datasets adhere to the P-code standard, their integration and analysis become efficient. The dataset provides comprehensive boundary information for Madagascar at five administrative levels: country, region, district, commune, and fokontany. It's accessible for download as shapefiles from [the provided link](https://data.humdata.org/dataset/cod-ab-mdg).

### Localities

The "Madagascar Populated Places" dataset is also part of the Common Operational Datasets (CODs). This dataset encompasses populated place points for Madagascar. The data has been sourced from the National Geospatial-Intelligence Agency and provided by the University of Georgia - ITOS. Further, the Geographic Information Support Team (GIST) has taken up the role of distributor, with the data being published on 2007-03-07. UN OCHA ROSA has enhanced the dataset by adding P-codes and administrative boundary names, which are based on the BNGRC (National Disaster Management Office) data. The dataset geolocates 28184 populated places with their toponyms (names), codes related to various administrative levels such as fokontany, commune, district, and region, and their spatial coordinates.

```{r}
# Load datasets
ROR_surveys_2007 <- read_dta("Données ROR/enter/2007/res_deb.dta")
observatory_names <- read_xlsx("Observatory_names.xlsx")
obs_communes <- st_read(
  "data/observatoires/Observatoires_ROR_communes_COD.gpkg",
  quiet = TRUE) %>%
  left_join(select(observatory_names, name, code), 
            by = c("OBS_NAME" = "name")) %>%
  rename(OBS_CODE = code)
pop_places <- st_read(
  "../entités administratives/OCHA_BNGRC populated places/mdg_pplp_places_NGA_OCHA.shp", quiet = TRUE)
```

## Methodology

### Simplify strings

The treatment of toponyms presents a unique challenge, especially when these names are captured from varied sources. In the dataset, these names can vary due to differences in languages, case sensitivity, and the inclusion of additional descriptive terms. To address this, the `clean_string` function was developed. This function begins by converting all strings to lowercase, ensuring that subsequent comparisons are not sensitive to case variations. Next, to create a uniform standard, all non-alphanumeric characters are removed, retaining only spaces and the alphanumeric content. Common qualifiers in toponyms, such as "centre", "haut" (high) or "bas" (low), which are not used consistently across records, are also removed. Given the bilingual nature of the dataset, with entries potentially in both Malagasy and French, the function translates cardinal points to the Malagasy language to ensure uniformity. Lastly, certain locales with multiple names, such as "Fort Dauphin", also known as "Taolagnaro", "Tolagnaro" or "Tolanaro", are standardized to a single term, "Tolanaro", to eliminate potential disparities.

```{r}
# A function to harmonize cases and usual variation in the way localities are 
# written in the survey data
clean_string <- function(x){
  x %>%
    tolower() %>% # Convert to lowercase
    # Retain spaces, remove other non-alphanumeric characters
    str_replace_all("[^[:alnum:][:space:]]", " ") %>% 
    str_remove_all("\\b(centre|haut|bas|androy)\\b") %>%
    str_trim() %>% # Trim spaces from start and end of string
    str_replace_all("\\bcentre\\b", "") %>% # Remove the word 'centre'
    # Translate cardinal points
    str_replace_all("\\bnord\\b", "avaratra") %>% 
    str_replace_all("\\best\\b", "atsinanana") %>%
    str_replace_all("\\bouest\\b", "andrefana") %>% 
    str_replace_all("\\bsud\\b", "atsimo") %>% 
    str_replace_all("\\batsinana\\b", "atsinanana") %>% # Replace short form 
    str_replace_all("(fort dauphin)|(taolagnaro)|(tolagnaro)", 
                    "tolanaro") # Variations for fort dauphin
    
}
```

### Fuzzy matching

By default, statistical softwares and computing language match text by pairing only identical strings. Exact string matching is inappropriate in our context, where location data entry was subject to human errors like typographical mistakes or minor variations in spelling. To counteract this rigidity, fuzzy matching is employed. This approach gauges the similarity between two strings, bypassing the need for an exact character-to-character match. The principle metric adopted for this is the "Levenshtein distance", which quantifies the minimum number of single-character edits required to change one string into another. The `fuzzy_match` function encapsulates this approach. The function initiates the process by filtering the reference list of encontered toponyms based on a given observatory code, which considerably narrows down potential matches. Then, using the Jaro-Winkler distance metric — a variant of the Levenshtein distance particularly suited for shorter strings — the function computes the similarity between the target string and entries in the filtered reference. To ensure that only relevant matches are acknowledged, a threshold, termed max_distance, is set. Matches that exceed this threshold are disregarded. For those that pass this validation, the function then extracts the pertinent details of the matched row from the reference dataframe.


```{r}
fuzzy_match <- function(target_string, dataframe, column_name, observatory_code, 
                        max_distance = 0.25) {
  # Filter the dataframe based on observatory_code
  filtered_reference <- dataframe %>%
    filter(OBS_CODE == observatory_code) %>%
    select(all_of(column_name), ADM3_PCODE, ADM3_EN)
  
  # If filtered_reference is empty, return NA values
  if (nrow(filtered_reference) == 0) {
    return(list(matched_string = NA, ADM3_PCODE = NA, ADM3_EN = NA, distance = 1))
  }
  
  # Use stringdist to find the closest match
  distances <- stringdist::stringdistmatrix(target_string, filtered_reference[[column_name]], method = "jw")
  
  # If there are no valid distances, set min_distance to Inf (this should help avoid the error)
  if(all(is.na(distances))) {
    min_distance <- Inf
  } else {
    min_distance <- min(distances, na.rm = TRUE)  # Ensure NA values don't affect the min calculation
  }
  
  # Check for Inf distance and replace it with 1
  if (is.infinite(min_distance)) {
    min_distance <- 1
  }
  
  # If min_distance exceeds the max_distance threshold, return NA values
  if (min_distance > max_distance) {
    return(list(matched_string = NA, ADM3_PCODE = NA, ADM3_EN = NA, distance = NA))
  }
  
  matched_row <- filtered_reference[which.min(distances), ]
  
  return(list(matched_string = matched_row[[column_name]], 
              ADM3_PCODE = matched_row$ADM3_PCODE, 
              ADM3_EN = matched_row$ADM3_EN, 
              distance = min_distance))
}
```

### Hierarchical matching of data

The hierarchical organization of spatial entities is key for our challenge. Such an organization allows for a cascading representation of data, from broader scopes narrowing down to more specific layers. This representation is reminiscent of the ontological order of geographical entities: regions contain provinces, which encompass municipalities, and these in turn house localities. In the georeferencing context, leveraging this hierarchical structure can lead to more precise matches. For instance, if an observatory code is associated with a specific district, the search for matches is confined to that distict, enhancing both the efficiency and accuracy of the process. @fig-spatial-hierarchies elucidates this hierarchical arrangement, serving as a roadmap for the subsequent data matching tasks.

```{mermaid}
graph TD

A[Legend]

W[ ]
X[ ]
Y[ ]
Z[ ]

W -->|Pre-definede hierarchy| X
Y -.-|Implemented matching|Z
```
```{mermaid}
%%| label: fig-spatial-hierarchies
%%| fig-cap: Spatial entities pre-defined relationship and matching


graph TD

%% Administrative Logic
subgraph "Administrative Logic"
A[Region]
B[District]
C[Commune]
D[Fokontany]
I[Populated places]

A --> B
B --> C
C --> D
D --> I
end

%% Observatory Logic

subgraph "Observatory Logic"
E[Observatory network]
F[Observatory]
G[Commune]
H[Village]
J[Site]

E --> F
F --> G
G --> H
F --> H
H--> J
end

%% Geospatial matching
H -.- I
C -.- G
```

The current administrative strucure is defined as follows, regions include Districs, which include communes which include Fokontany. Fokontany refers on principles to a village, but in practice it often encompasses a series of villages or populated places. Note that communes where formalized in 1994 but their implementation took time. The concept of "communes" predates 1994, but before the decentralizatoin law they were merely a administrative representation of the local government. Regions were created in 2004.
On the ROR side, observatory refereed during the first surveys to villages. A systematic registry of the communes only started in the 2004 and 2005 round, depending on the observatories. A mention to "sites" also appeared in 2011 but was scarcely documented.
Our strategy was to established links between the village information and populated places, and between communes.

## A Detailed walk-through

As a starting point we browsed the documentation and documented, in the COD subnational data adding a field `OBS_Y_N`, with the value 1 if the municipality was reported as included into an observervatory survey (or empty otherwise), and `OBS_NUM` with the number of the corresponding observatory (or empty if not reported as surveyed). The list of observatory and corresponding surveyed municipalities is presented in the \[table X\].

The process followed then applied 4 subsequent geolocation phases, all of which are totally n the completeness/quality of the data obtained in the previous steps, so we follow it by

### Method 1

Where we have municipality names in the corresponding field: match these names with the names of the municipalities already identified as data collection sites (the matching is segmented observatory by observatory to reduce the risk). There might be some writing variations so we use fuzzy matching, checking for the likelihood to have a valid match (and maybe enable a visual confirmation)

```{r}
# List of years
years <- 1995:2014

# Read all datasets and combine
all_surveys_description <- map_df(years, function(year) {
  df <- read_dta(paste0("Données ROR/enter/", year, "/res_deb.dta"))
    # Convert all columns to character to ensure consistency
  df <- df %>% mutate_all(as.character)
  return(df)
})

# Extract unique combinations and list all the years they appeared in
unique_combinations <- all_surveys_description %>%
  group_by(j0, j42, j4) %>%
  summarize(years = toString(year)) %>%
  ungroup()

# Harmonize the fields that contain municipality or village names
unique_combinations <- unique_combinations %>%
  mutate(clean_muni = clean_string(j42),
         clean_village = clean_string(j4))
obs_communes <- obs_communes %>%
  mutate(clean_ADM3 = clean_string(ADM3_EN))
pop_places <- pop_places %>%
  mutate(clean_pname = clean_string(PLACE_NAME)) 

# List of observatories for which municipalities have been identified
identified_observatories <- unique(obs_communes$OBS_CODE) %>%
  na.omit()
# Filter for the observatory for which we already have a manual identification
# of municipalities
unique_combinations <- unique_combinations %>%
  filter(j0 %in% identified_observatories) 

# Apply the fuzzy matching observatory-wise
results <- map2_df(unique_combinations$clean_muni, 
                   unique_combinations$j0, 
                   ~ as.data.frame(t(
                     fuzzy_match(.x, obs_communes, "clean_ADM3", .y))))  %>%
  unnest(cols = c(matched_string, distance, ADM3_PCODE, ADM3_EN))

# Combine the results with the unique_combinations
correspondence_table <- bind_cols(unique_combinations, results) 

# Add a column for the matching method
correspondence_table <- correspondence_table %>%
  mutate(method = ifelse(!is.na(matched_string), "method_1", NA_character_))
```

We can visualize the output of this matches in a map.

```{r}
# Extract matched resuts
matched_results <- unique(correspondence_table$ADM3_PCODE) %>%
  na.omit()
# Keep municipalities in those
matched_spatial <- obs_communes %>%
  filter(ADM3_PCODE %in% matched_results)

tmap_mode("view")
# Plot
tm_shape(matched_spatial) +
  tm_polygons(col = "OBS_NAME")
```

### Method 2

For observations that had no municipality name. Try parsing the strings in the village name field to see if they contain a municipality name of a municipality already identified within the observatory surveyed municipalities.

```{r}
# Filter out matched municipalities and extract the first word
unmatched_results <- correspondence_table %>%
  filter(is.na(matched_string)) %>%
  select(j0:clean_village) %>%
  mutate(first_word = str_extract(clean_village, "^[^\\s/]+"))

# Fuzzy matching with the first word and identified municipalities
results_step2 <- map2_df(unmatched_results$first_word, 
                         unmatched_results$j0, 
                         ~ as.data.frame(t(
                           fuzzy_match(.x, obs_communes, "clean_ADM3", .y))))  %>%
  unnest(cols = c(matched_string, distance, ADM3_PCODE, ADM3_EN))

# Update Results
potential_matches2 <- bind_cols(unmatched_results, results_step2)

# Manually identify false positives and remove them
false_positives <- c("madiromionga", "maroarla", "tsaratanteraka", 
                    "ambatoharanana", "ambatoaranana", "maroala", "erakoja", 
                    "erakoka", "maroalo", "erakka", "erakoa")
validated_matches2 <- potential_matches2 %>%
  mutate(across(c(matched_string, ADM3_PCODE, ADM3_EN, distance),
               ~ ifelse(first_word %in% false_positives, NA, .)),
         method = ifelse(!is.na(matched_string), "method_2", NA_character_))

# Integrate new results in correspondence table
correspondence_table <- correspondence_table %>%
  filter(!is.na(matched_string)) %>%
  bind_rows(validated_matches2)
```

### Method 3

Now let's see if I have clo

```{r}
# Re-filter unmatched results
unmatched_results2 <- correspondence_table %>%
  filter(is.na(matched_string)) %>%
  select(j0:clean_village)

# Join OBS_CODE to pop_places
pop_places <- pop_places %>%
  rename(ADM3_PCODE = COM_PCODE, ADM3_EN = COMMUNE) %>%
  mutate(ADM3_PCODE = str_replace(ADM3_PCODE, "^MDG", "MG")) %>%
  left_join(select(obs_communes, ADM3_PCODE, OBS_CODE) %>%
                     st_drop_geometry(), 
            by = "ADM3_PCODE")

# Apply the fuzzy matching observatory-wise
results_step3 <- map2_df(unmatched_results2$clean_village, 
                         unmatched_results2$j0, 
                         ~ as.data.frame(t(
                           fuzzy_match(.x, pop_places, "clean_pname", .y,
                                       max_distance = 0.22))))  %>% # erratic results beyond
  unnest(cols = c(matched_string, distance, ADM3_PCODE, ADM3_EN))

# Bind the results with unmatched_results_v2
potential_matches3 <- bind_cols(unmatched_results2, results_step3)

# Manually identify false positives and remove them
false_positives2 <- c("analambarika", "maroaloka", "ambakela", "ambodirofia",
                      "ambohibao", "ambato mangabe", "marofonaritra", 
                      "andranovo ambodimanga", "morataitra", "antanambao", 
                      "ankililoa")
validated_matches3 <- potential_matches3 %>%
  mutate(across(c(matched_string, ADM3_PCODE, ADM3_EN, distance),
               ~ ifelse(clean_village %in% false_positives2, NA, .)),
         method = ifelse(!is.na(matched_string), "method_3", NA_character_))

correspondence_table <- correspondence_table %>%
  filter(!is.na(matched_string)) %>%
  bind_rows(validated_matches3)
```

### Method 4

For the remaining, let's try matching with other village names for which municipality has been matched.

```{r}
# Create a list of municipality names and village names for matched observations
matched_villages <- correspondence_table %>%
  filter(!is.na(method)) %>%
  select(j0, ADM3_PCODE, ADM3_EN, clean_village) %>%
  distinct() %>%
  rename(OBS_CODE = j0)

# Re-filter unmatched results
unmatched_results3 <- correspondence_table %>%
  filter(is.na(method)) %>%
  select(j0:clean_village)

# Try matching unmatched villages against matched village names observatory-wise
results_village_match <- map2_df(
  unmatched_results3$clean_village, unmatched_results3$j0,
  ~ as.data.frame(t(fuzzy_match(.x, matched_villages, "clean_village",
                                .y, max_distance = 0.28)))) %>%
  unnest(cols = c(matched_string, distance, ADM3_PCODE, ADM3_EN))
# Bind these results with unmatched_results_v3
potential_matches4 <- bind_cols(unmatched_results3, results_village_match)

# Manually identify false positives and remove them
false_positives4 <- c("amp0mbibitika antanakova", "arakoke ambonano ampihamibe", 
                      "farara farara", "farara ambakela", "fara ambakela", 
                      "ambatotelo marofinaritra")
validated_matches4 <- potential_matches4 %>%
  mutate(across(c(matched_string, ADM3_PCODE, ADM3_EN, distance),
               ~ ifelse(clean_village %in% false_positives4, NA, .)),
         method = ifelse(!is.na(matched_string), "method_4", NA_character_))


# Merge the updated results back to the correspondence table
correspondence_table <- correspondence_table %>%
  filter(!is.na(matched_string)) %>%
  bind_rows(validated_matches4)
```

## Matching villages

Now we will georeference the villages.

```{r}
fuzzy_match_village <- function(target_string, dataframe, column_name, ADM3_PCODE_filter, 
                                max_distance = 0.25) {
  
  filtered_reference <- dataframe %>%
                          filter(ADM3_PCODE == ADM3_PCODE_filter) %>%
                          select(all_of(column_name), P_PCODE, longitude, latitude)
  
  # If filtered_reference is empty, return NA values
  if (nrow(filtered_reference) == 0) {
    return(list(matched_string = NA, P_PCODE = NA, geometry = NA, distance = 1))
  }
  
  # Use stringdist to find the closest match
  distances <- stringdist::stringdistmatrix(target_string, filtered_reference[[column_name]], method = "jw")
  
  # If there are no valid distances, set min_distance to Inf
  if(all(is.na(distances))) {
    min_distance <- Inf
  } else {
    min_distance <- min(distances, na.rm = TRUE)
  }
  
  # Check for Inf distance and replace it with 1
  if (is.infinite(min_distance)) {
    min_distance <- 1
  }
  
  # If min_distance exceeds the max_distance threshold, return NA values
  if (min_distance > max_distance) {
    return(list(matched_string = NA, P_PCODE = NA, geometry = NA, distance = NA))
  }
  
  matched_row <- filtered_reference[which.min(distances), ]
  
  return(list(matched_string2 = matched_row[[column_name]], 
              P_PCODE = matched_row$P_PCODE, 
              longitude = matched_row$longitude,
              latitude = matched_row$latitude,
              distance2 = min_distance))
}

# Extract coordinates from pop_places
coords <- data.frame(st_coordinates(pop_places$geometry))

# Add these as columns in pop_places
pop_places$longitude <- coords[, "X"]
pop_places$latitude <- coords[, "Y"]



# Apply the modified fuzzy match
results_village_geom <- pmap_df(
  list(clean_village = correspondence_table$clean_village, 
       ADM3_PCODE = correspondence_table$ADM3_PCODE), 
  function(clean_village, ADM3_PCODE) {
    as.data.frame(t(fuzzy_match_village(clean_village, pop_places, "clean_pname", ADM3_PCODE)))
  }
)

# Combine the results with correspondence_table
correspondence_table_updated <- bind_cols(correspondence_table, results_village_geom)

```

## Validating the Quality of Georeferenced Data

### Quantitative metrics

We assess the unique observations that could be matched at each steps.

```{r}
correspondence_table %>%
  mutate(`Geolocated municipalities at step 1` = 
           ifelse(is.na(method), "Unmatched", "Matched")) %>%
  group_by(`Geolocated municipalities at step 1`, is.na(j42)) %>% 
  summarise(N = n()) %>%
  mutate(Percentage = (N / sum(N) * 100),
         Percentage = round(Percentage, 1)) %>%
  gt()
```

### Consistency check with documentation

Check that we have villages in all the municipalities

Comparison with the ROR registries

### Visual exploration and avenues for continuous corrections

Visualizing the data

```{r}
# Extract matched results
matched_results <- unique(correspondence_table$ADM3_PCODE) %>%
  na.omit()

# Keep municipalities in those
matched_spatial <- obs_communes %>%
  filter(ADM3_PCODE %in% matched_results)

#############################################################################
# Big problem with spatial coordianates TO SOLVE LATER
# Handle NULL values by assigning them NA
correspondence_table_updated$longitude[sapply(correspondence_table_updated$longitude, is.null)] <- NA
correspondence_table_updated$latitude[sapply(correspondence_table_updated$latitude, is.null)] <- NA

# Convert the remaining list items to numeric
correspondence_table_updated$longitude <- sapply(correspondence_table_updated$longitude, function(x) {
  if (is.list(x) && !is.null(x[[1]])) {
    return(as.numeric(x[[1]]))
  } else {
    return(as.numeric(x))
  }
})

correspondence_table_updated$latitude <- sapply(correspondence_table_updated$latitude, function(x) {
  if (is.list(x) && !is.null(x[[1]])) {
    return(as.numeric(x[[1]]))
  } else {
    return(as.numeric(x))
  }
})
# Filter rows where both longitude and latitude are not NA
correspondence_table_updated <- correspondence_table_updated[!is.na(correspondence_table_updated$longitude) & 
                                                            !is.na(correspondence_table_updated$latitude), ]
# Convert to sf object
correspondence_sf <- st_as_sf(correspondence_table_updated, coords = c("longitude", "latitude"), crs = 4326)
#########################################################################

Vahatra <- st_read("../Aires protégées/Vahatra/Shapefiles/AP_Vahatra.shp", 
                   quiet = TRUE)

# Plot
tmap_mode("view")
tm_shape(matched_spatial) +
  tm_polygons(col = "OBS_NAME") +
  tm_shape(correspondence_sf) + 
  tm_dots(alpha = 0.5, size = 0.1) +
  tm_shape(Vahatra) +
  tm_polygons(col = "green", alpha = 0.3) +
  tmap_options(check.and.fix = TRUE)

```

Addressing and Rectifying Discrepancies

## Conclusion

Key Findings and Takeaways Recommendations for Further Improvement in Data Georeferencing
