{
  "hash": "f24d508621563c07353661ca6ef5c247",
  "result": {
    "markdown": "---\noutput: html_document\neditor_options: \n  chunk_output_type: console\n---\n\n\n# Data preparation\n\nIn this section, we describe and reproduce the procedure followed to prepared the Rural Observatory System (ROS) data. This process entails selecting the relevant files and organizing them in the local file system, removing the names and replacing them with pseudonyms, enriching the metadata with table names, and converting the file formats to propose an open standard version alongside STATA.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)    # A series of packages for data manipulation\nlibrary(haven)        # Required for reading STATA files (.dta)\nlibrary(tidyverse)\nlibrary(stringdist)\nlibrary(tictoc)\nlibrary(progressr)\nlibrary(future)\nlibrary(furrr)\nlibrary(gt)\nlibrary(readxl)\n```\n:::\n\n\n\n## Data selection\n\nFirst we start with creating a copy of the original unfiltered and un-anonymized data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the paths for the source and target folders\nsource_folder <- \"data/ROS_data_original\"\ntarget_folder <- \"data/ROS_data_prepared\"\n\n# Create the target folder if it does not exist\nif (!dir.exists(target_folder)) {\n  dir.create(target_folder, recursive = TRUE)\n}\n\n# Empty the target folder if it already contains files\nif (length(list.files(target_folder, recursive = TRUE)) > 0) {\n  # List all files within the target folder recursively\n  files_to_remove <- list.files(target_folder, full.names = TRUE, recursive = TRUE)\n  # Remove these files\n  file.remove(files_to_remove)\n}\n\n# Function to recursively copy files from source to target\ncopy_files <- function(source, target) {\n  # Ensure the target directory exists\n  if (!dir.exists(target)) {\n    dir.create(target, recursive = TRUE)\n  }\n  \n  # List all files and directories in the source\n  contents <- list.files(source, full.names = TRUE)\n  \n  # Separate files and directories\n  dirs <- contents[which(sapply(contents, function(x) file.info(x)$isdir))]\n  files <- contents[which(sapply(contents, function(x) !file.info(x)$isdir))]\n  \n  # Copy files\n  if (length(files) > 0) {\n    file.copy(files, target, overwrite = TRUE)\n  }\n  \n  # Recursively copy directories\n  if (length(dirs) > 0) {\n    for (dir in dirs) {\n      new_source <- dir\n      new_target <- file.path(target, basename(dir))\n      copy_files(new_source, new_target)\n    }\n  }\n}\n\n# Copy all files and folders from source to target\ncopy_files(source_folder, target_folder)\n```\n:::\n\n\nFor 2015, we have 4 observatories. One that existed on the previous years, Menabe Nord-Est, and 3 new ones: Ambatofinandrahana, Anjozorobe et Maintirano. The data collection of the ROS kept on until 2017, but we lack documentation since 2015 and the data has not yet been harmonized for 2016 and 2017. For this reason, we only kept the data for Menabe North-East for 2015.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the path to the 2015 folder within the target folder\nfolder_2015 <- \"data/ROS_data_prepared/2015\"\n\n# List all .dta files in the 2015 folder\ndta_files <- list.files(folder_2015, pattern = \"\\\\.dta$\", full.names = TRUE)\n\n# Initialize a variable to track if all files were successfully filtered\nall_files_filtered <- TRUE\n\n# Loop through each .dta file\nfor (file_path in dta_files) {\n  # Load the dataset\n  data <- read_dta(file_path)\n  \n  # Check if 'j5' exists and is a character variable\n  if (\"j5\" %in% names(data) && is.character(data$j5)) {\n    # Filter for j5 == \"52\"\n    filtered_data <- data[data$j5 == \"52\", ]\n    \n    # Save the filtered dataset back to the same file (or to a new file/path)\n    write_dta(filtered_data, file_path)\n  } else {\n    # Set the flag to FALSE if j5 does not exist or is not character in any file\n    all_files_filtered <- FALSE\n    break  # Exit the loop as we found a file not meeting the criteria\n  }\n}\n\n# Check if all files were successfully filtered and print a message\nif (!all_files_filtered) {\n  cat(\"Error: Not all files were filtered. At least one file does not contain 'j5' as a character variable.\")\n}\n```\n:::\n\n\nIf no error message is displayed, the filtering went on correctly.\n\n## Data anonymization\n\nDuring the rural observatory surveys, the names of the household members were collected in the questionnaire called the roaster. To prevent re-identification of personal data, we will replace these names with pseudonyms such as \"individual_01\", \"individual_02\", and so on. These pseudonyms are not related to the original names and individuals with the same name in different households will be given different pseudonyms. However, the same household members will have the same pseudonym in subsequent surveys. For example, in a particular household, \"individual_05\" in 1998 is the same person as \"individual_05\" in the 1999, 2000, 2001, and 2002 survey rounds.\n\nThe main challenge with this procedure is that the names were provided orally by the respondent, written down by the surveyors, and later entered into the system by data entry clerks. As a result, we have a wide range of variations in the character strings in our data, even though they correspond to the names of the same individuals. To carry out this pseudonymization process, we follow several steps that involve fuzzy matching and consistency checks with individual age and sex. We begin by loading and consolidating the content of the survey roasters for all survey years.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Usage\nros_data_loc <- \"data/ROS_data_prepared/\"\nyears <- 1995:2015\n\n# Normalizing function as you've provided\nnormalize_name <- function(name) {\n  name %>%\n    stringi::stri_trans_general(\"Latin-ASCII\") %>%\n    str_to_lower() %>%\n    str_replace_all(\"[^a-z ]\", \"\") %>%\n    str_trim()\n}\n\n# Function to read and preprocess data\nread_and_normalize <- function(year, ros_data_loc) {\n  \n  file_name <- if (year == 1995) \"res_m.dta\" else \"res_m_a.dta\"\n  file_path <- file.path(ros_data_loc, as.character(year), file_name)\n  \n  if (!file.exists(file_path)) return(NULL)\n  \n  read_dta(file_path) %>%\n    select(m1, year, j5, m4, m5) %>%\n    mutate(m5 = as.numeric(m5),\n           name_normalized = normalize_name(m1),\n           line_number = row_number())\n}\n\nall_data <- map_df(years, ~read_and_normalize(.x, ros_data_loc))\n\n# Get a list of unique household IDs\nhousehold_ids <- unique(all_data$j5)\n\n# Count household ids and observations\nnb_hh <- nrow(household_ids)\nnb_i <- nrow(all_data)\n```\n:::\n\n\nWe have a total 590 524 individual observations of 29 493 unique households. To match name variations within subsequent surveys of the same household, we use the Jaro-Winkler algorithm as implemented in the \\`stringdist\\` package and described as followed by the package author [@vanderloo2014a, p. 119]:\n\n> \"The Jaro distance was originally developed at the U.S. Bureau of the Census for the purpose of linking records based on inaccurate text Ô¨Åelds. (...) It has been been successfully applied to statistical matching problems concerning fairly short strings, typically name and address data [@jaro1989]. The reasoning behind the Jaro distance is that character mismatches and transpositions are caused by typing or phonetic transcription errors but matches between remote characters are unlikely to be caused by such kind of errors. (...) Winkler [-@winkler1990] extended the Jaro distance by incorporating an extra penalty for character mismatches in the first four characters. (...) The reasoning is that apparently, people are less apt to make mistakes in the first four characters or perhaps they are more easily noted, so differences in the first four characters point to a larger probability of two strings being actually different.\"\n\nWe refined a procedure that applies this algorithm in three steps:\n\n1.  **Initial reference:** the initial survey year of each household, member names are cataloged to serve as a reference;\n2.  **Close Match Identification:**For each ensuing survey, we scout for names that not only exhibit the smallest Jaro-Winkler distance from the reference names but also fall below a stringent threshold of 0.2 (ie. we only take in account the name when the names are very similar);\n3.  **Expanded Criteria for Matches:** Absence of matches at step 2. for a given year prompts an extended search within the household, this time accommodating names with a distance below 0.3 if they align in sex and age, accounting for a 5-year margin to mitigate inaccuracies in age recall (ie. we allow for slightly more dissimilar names if sex and age match);\n4.  **Validation of Matches:** For each match identified at step 2. or 3., we verify that there is no other household member name that is a better match based on the Jaro-Winkler distance. If so, we remove it from the matched names.\n5.  **Pseudonym Assignment:** matched names get a pseudonym \"Individual_XX\", with \"XX\" representing a sequential number..\n6.  **Sequential Application:** this procedure iterates through all names from the initial survey year, extending to unmatched names in subsequent years, thereby ensuring comprehensive coverage.\n\nThe code was adapted to handle gracefully edge cases, for instance when sex data or age is missing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npseudonymize_household <- function(pool, distance_threshold1 = 0.2, \n                                   distance_threshold2 = 0.3,\n                                   tolerance_yeardiff = 5) {\n  years <- unique(pool$year) # extract list of existing years in dataset\n  pseudonymized <- data.frame() # create empty dataframe\n  next_pseudonym_id <- 1 # initialize the pseudonym id\n  \n  for (current_year in years) {\n    staging <- subset(pool, year == current_year)\n    # For subsequent years, attempt to match with existing pseudonyms\n    for (i in seq_len(nrow(staging))) {\n      name <- staging$name_normalized[i]\n      sex <- staging$m4[i]\n      age <- staging$m5[i]\n      \n      pool <- pool %>%\n        mutate(dist = stringdist(name_normalized, name, method = \"jw\"),\n               age_diff = abs(m5 - age - (year - current_year))) %>%\n        group_by(year) %>%\n        mutate(\n          match = case_when(\n            # First level of matching based on distance_threshold1\n            dist == min(dist) & dist < distance_threshold1 ~ \"matched\",\n            \n            # Second level of matching based on distance_threshold2\n            dist == min(dist) & dist < distance_threshold2 & \n              (is.na(m4) | m4 == sex) & age_diff <= tolerance_yeardiff ~ \"matched\",\n            TRUE ~ \"unmatched\"), # default\n          pseudonym = ifelse(match == \"matched\", \n                             sprintf(\"individual_%02d\", next_pseudonym_id), \n                             NA_character_)) %>%\n        ungroup()\n      \n      # Ensure 'match' column is explicitly treated as a character\n      pool$match <- as.character(pool$match)\n      \n      # Then perform the operation to compute min_dist_unmatch and re-evaluate 'match'\n      if (any(pool$match == \"matched\")) {\n        unmatched_names <- pool$name_normalized[pool$match == \"unmatched\"]\n        pool <- pool %>%\n          rowwise() %>%\n          mutate(min_dist_unmatch = if_else(match == \"matched\" & \n                                              length(unmatched_names) > 0,\n                                            min(stringdist(name_normalized, \n                                                           unmatched_names, \n                                                           method = \"jw\"), \n                                                na.rm = TRUE),\n                                            NA_real_),\n                 match = if_else(match == \"matched\" & min_dist_unmatch < dist & \n                                   !is.na(min_dist_unmatch), \"unmatched\", match),\n                 pseudonym = if_else(match == \"unmatched\", NA_character_, \n                                     pseudonym)) %>%\n          ungroup()\n      }\n     \n      # Identify and adjust duplicate pseudonyms within the same year for matched cases\n      pool <- pool %>%\n        group_by(year, pseudonym) %>%\n        mutate(dup_count = n()) %>%\n        ungroup() %>%\n        mutate(is_dup = ifelse(dup_count > 1 & match == \"matched\", TRUE, FALSE)) %>%\n        group_by(year, pseudonym) %>%\n        mutate(dup_rank = ifelse(is_dup, row_number(), NA_integer_)) %>%\n        ungroup() %>%\n        mutate(match = ifelse(is_dup & dup_rank > 1, \"unmatched\", match),\n               pseudonym = ifelse(is_dup & dup_rank > 1, NA_character_, pseudonym)) %>%\n        select(-dup_count, -is_dup, -dup_rank)\n\n      \n      pool$match <- as.character(pool$match)\n      pool$pseudonym <- as.character(pool$pseudonym)\n      \n      pseudonymized <- pseudonymized %>%\n        bind_rows(filter(pool, match == \"matched\"))\n      pool <- filter(pool, match != \"matched\")\n      next_pseudonym_id <- next_pseudonym_id + 1\n    }\n  }\n  return(pseudonymized)\n}\n\n# The following process is very long (~1h with a good computer)\n# We only run it once\npseudo_loc <- \"output/pseudonymized_all.rds\"\n\nif (!file.exists(pseudo_loc)) {\n  # Set up parallel plan\n  plan(multisession, workers = 6)\n  \n  # Define your processing function to include progress signaling\n  process_household_with_progress <- function(household_id, .progress) {\n    .progress()  # Signal progress update\n    pool <- all_data %>% filter(j5 == household_id)\n    pseudonymized <- pseudonymize_household(pool)\n    return(pseudonymized)\n  }\n  \n  # tic()\n  # Wrap processing in with_progress\n  pseudonymized_all <- with_progress({\n    # Create a progressor function inside with_progress\n    p <- progressor(along = household_ids)\n    \n    future_map_dfr(household_ids\n                   , ~process_household_with_progress(.x, p), .progress = FALSE)\n  })\n  # toc() # 3197.55 sec elapsed, 53 minutes\n  \n  write_rds(pseudonymized_all, pseudo_loc)\n} else { # Otherwise we read the existing milestone\n  pseudonymized_all <- read_rds(pseudo_loc)\n}\n\nfor (year in years) {\n  \n  # Determine the file name based on the year\n  file_name <- if (year == 1995) \"res_m.dta\" else \"res_m_a.dta\"\n  file_path <- file.path(ros_data_loc, as.character(year), file_name)\n  \n  # Read the full dataset for the year\n  res_m <- read_dta(file_path) %>%\n    mutate(m5 = as.numeric(m5),  # Convert m5 to numeric\n           line_number = row_number())\n  \n  # Merge pseudonym information from pseudonymized_all\n  res_m_with_pseudonym <- res_m %>%\n    left_join(pseudonymized_all %>% \n                select(m1, j5, m4, m5, year, line_number, pseudonym), \n              by = c(\"m1\", \"j5\", \"m4\", \"m5\", \"line_number\", \"year\")) %>%\n    relocate(pseudonym, .after = m1) %>% # Move pseudonym column after m1 if needed\n    select(-m1, -line_number)\n  \n  # Check for missing pseudonym values\n  missing_pseudonyms <- sum(is.na(res_m_with_pseudonym$pseudonym))\n  if (missing_pseudonyms > 0) {\n    stop(paste(\"Error: Missing pseudonym values found in year\", year, \n               \"- Total missing:\", missing_pseudonyms))\n  }\n  \n  # Write the dataset back to a Stata file\n  write_dta(res_m_with_pseudonym, file_path)\n}\n```\n:::\n\n\nAfter this process, the column \"m1\" containing the name of household members has been removed from all the data files and it has been replaced by the column \"pseudonym\". While anonymizing the data, this process enabled the tracking of repeated observations of the same individuals. We are now able to compute the number of unique individuals that have been surveyed throughout the ears\n\n\n::: {#tbl-ind-number-ros .cell tbl-cap='Number of observations and unique entities in the ROR data from 1995 to 2015'}\n\n```{.r .cell-code}\npseudo_loc <- \"output/pseudonymized_all.rds\"\npseudonymized_all <- read_rds(pseudo_loc)\n\n# Total number of individual observations\ntotal_individual_observations <- nrow(pseudonymized_all)\n\n# Total number of unique households\nunique_households <- pseudonymized_all %>% \n  distinct(j5) %>% \n  nrow()\n\n# Total number of household observations across years\nhousehold_observations_across_years <- pseudonymized_all %>% \n  group_by(year) %>% \n  summarise(n_distinct_j5 = n_distinct(j5)) %>% \n  summarise(total = sum(n_distinct_j5))\n\n# Average number of times a household was surveyed\naverage_surveys_per_household <- pseudonymized_all %>% \n  group_by(j5) %>% \n  summarise(n_surveys = n_distinct(year)) %>% \n  summarise(average = mean(n_surveys))\n\n# Number of unique individuals (considering both household ID and pseudonym)\nunique_individuals <- pseudonymized_all %>% \n  distinct(j5, pseudonym) %>% \n  nrow()\n\n# Average number of times an individual was surveyed\naverage_surveys_per_individual <- total_individual_observations / unique_individuals\n\n# Creating a summary table\nsummary_table <- tibble(\n  Unique_households = unique_households,\n  Household_observations = household_observations_across_years$total,\n  Average_surveys_per_household = average_surveys_per_household$average,  \n  Unique_individuals = unique_individuals,\n  Individual_observations = total_individual_observations,\n  Average_surveys_per_individual = average_surveys_per_individual) %>% \n  pivot_longer(cols = everything(), names_to = \"Metric\", values_to = \"Value\") %>%\n  mutate(Metric = str_replace_all(Metric, \"_\", \" \"),\n         FormattedValue = case_when(\n           Value == floor(Value) ~ format(as.integer(Value), big.mark = \",\"),\n           TRUE ~ sprintf(\"%.2f\", Value)))\n\ngt(summary_table)  %>%\n  cols_label(FormattedValue = \"Value\") %>% # Renaming 'Value' to 'Formatted Value' for display\n  cols_hide(column = \"Value\") # Optionally hide the original 'Value' column\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"qxogkgjgqn\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#qxogkgjgqn table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#qxogkgjgqn thead, #qxogkgjgqn tbody, #qxogkgjgqn tfoot, #qxogkgjgqn tr, #qxogkgjgqn td, #qxogkgjgqn th {\n  border-style: none;\n}\n\n#qxogkgjgqn p {\n  margin: 0;\n  padding: 0;\n}\n\n#qxogkgjgqn .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#qxogkgjgqn .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#qxogkgjgqn .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#qxogkgjgqn .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#qxogkgjgqn .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#qxogkgjgqn .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#qxogkgjgqn .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#qxogkgjgqn .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#qxogkgjgqn .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#qxogkgjgqn .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#qxogkgjgqn .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#qxogkgjgqn .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#qxogkgjgqn .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#qxogkgjgqn .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#qxogkgjgqn .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#qxogkgjgqn .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#qxogkgjgqn .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#qxogkgjgqn .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#qxogkgjgqn .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#qxogkgjgqn .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#qxogkgjgqn .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#qxogkgjgqn .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#qxogkgjgqn .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#qxogkgjgqn .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#qxogkgjgqn .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#qxogkgjgqn .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#qxogkgjgqn .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#qxogkgjgqn .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#qxogkgjgqn .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#qxogkgjgqn .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#qxogkgjgqn .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#qxogkgjgqn .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#qxogkgjgqn .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#qxogkgjgqn .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#qxogkgjgqn .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#qxogkgjgqn .gt_left {\n  text-align: left;\n}\n\n#qxogkgjgqn .gt_center {\n  text-align: center;\n}\n\n#qxogkgjgqn .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#qxogkgjgqn .gt_font_normal {\n  font-weight: normal;\n}\n\n#qxogkgjgqn .gt_font_bold {\n  font-weight: bold;\n}\n\n#qxogkgjgqn .gt_font_italic {\n  font-style: italic;\n}\n\n#qxogkgjgqn .gt_super {\n  font-size: 65%;\n}\n\n#qxogkgjgqn .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#qxogkgjgqn .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#qxogkgjgqn .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#qxogkgjgqn .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#qxogkgjgqn .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#qxogkgjgqn .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#qxogkgjgqn .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Metric\">Metric</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Value\">Value</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Metric\" class=\"gt_row gt_left\">Unique households</td>\n<td headers=\"FormattedValue\" class=\"gt_row gt_right\"> 30,972</td></tr>\n    <tr><td headers=\"Metric\" class=\"gt_row gt_left\">Household observations</td>\n<td headers=\"FormattedValue\" class=\"gt_row gt_right\">102,733</td></tr>\n    <tr><td headers=\"Metric\" class=\"gt_row gt_left\">Average surveys per household</td>\n<td headers=\"FormattedValue\" class=\"gt_row gt_right\">3.32</td></tr>\n    <tr><td headers=\"Metric\" class=\"gt_row gt_left\">Unique individuals</td>\n<td headers=\"FormattedValue\" class=\"gt_row gt_right\">228,060</td></tr>\n    <tr><td headers=\"Metric\" class=\"gt_row gt_left\">Individual observations</td>\n<td headers=\"FormattedValue\" class=\"gt_row gt_right\">598,965</td></tr>\n    <tr><td headers=\"Metric\" class=\"gt_row gt_left\">Average surveys per individual</td>\n<td headers=\"FormattedValue\" class=\"gt_row gt_right\">2.63</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\nAs we see in the @tbl-ind-number-ros, we have 598,965 unique individuals that were surveyed in average 2.63 times.\n\n## Table labelling\n\nWe add labels to the STATA tables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the Excel file containing file names and labels\nfile_labels <- read_excel(\"references/file_labels.xlsx\")\n\n# Check and trim labels to 80 characters, and collect filenames needing trimming\nfile_labels <- file_labels %>% \n  mutate(needs_trimming = nchar(title_en) > 80,\n         title_en = if_else(needs_trimming, substr(title_en, 1, 80), title_en))\nfiles_with_trimmed_labels <- file_labels %>% \n  filter(needs_trimming) %>%\n  pull(filename)\n\n# Warn if any labels were trimmed\nif (length(files_with_trimmed_labels) > 0) {\n  warning(\"Labels for the following files were trimmed to 80 characters: \", paste(files_with_trimmed_labels, collapse = \", \"))\n}\n# res_ccp3.dta, rx_jn.dta, rx_tj4.dta, rx_tj5.dta \n\n\n# Define the base path for your folders\nbase_path <- \"data/ROS_data_prepared\"\n\n# Get the list of yearly folders using base R\nyear_folders <- list.dirs(base_path, full.names = TRUE, recursive = FALSE)\n\n# Function to read, check label length, and write .dta files\nprocess_files <- function(year_folder) {\n  dta_files <- list.files(year_folder, pattern = \"\\\\.dta$\", full.names = TRUE)\n  \n  purrr::walk(dta_files, function(file_path) {\n    file_name <- basename(file_path)\n    \n    # Find corresponding label in the file_labels dataframe\n    label <- file_labels %>%\n      filter(filename == file_name) %>%\n      pull(title_en) %>%\n      first()\n    \n    # Proceed only if label is found\n    if (!is.na(label)) {\n      data <- read_dta(file_path)\n      # Write the .dta file back with the new label\n      write_dta(data, file_path, label = label)\n    } \n  })\n}\n\n# Process files in each year folder\npurrr::walk(year_folders, process_files)\n```\n:::\n\n\n*To be completed*\n\n## Data format conversions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Install the latest version of DDIwR\nremotes::install_github(\"https://github.com/dusadrian/DDIwR\")\nlibrary(DDIwR)\n\n# Test on one package\n\ntest_file <- (\"data/ROS_data_prepared/2010/res_m_a.dta\")\n\nconvert(from = test_file,\n        to = \"output/test.xml\")\nconvert(from = test_file,\n        to = \"output/test.rds\",\n        )\n\ntest <- read_rds(\"output/test.rds\")\n\ntest2 <- read_dta(test_file)\n```\n:::\n\n\n*To be completed*\n",
    "supporting": [
      "04-ros-data-preparation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}